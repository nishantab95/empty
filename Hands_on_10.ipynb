{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1-2CknMQKvi"
      },
      "source": [
        "### Objective\n",
        "\n",
        "The objective of this notebook is to provide hands-on experience with **PySpark** for basic data processing tasks. Learners will:\n",
        "\n",
        "- Load structured data from a **CSV file** using PySpark  \n",
        "- Perform transformations using custom Python functions and register them as **User Defined Functions (UDFs)**  \n",
        "- Classify flower characteristics based on **petal length** and **sepal width**  \n",
        "- Save transformed data into multiple formats: **JSON** and **Parquet**  \n",
        "- Create and export a new DataFrame to **CSV** and **TSV** formats  \n",
        "- Understand the differences and benefits of using various **data storage formats**  \n",
        "\n",
        "This exercise helps learners gain practical skills in working with **PySpark's DataFrame API**, **UDFs**, and **file I/O operations**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXyJNOOvB6RP",
        "outputId": "dfcdb651-9b28-498e-95b1-f001d48adfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Plr9AWAl09"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark CSV Transformation\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMldvBlvBEPf",
        "outputId": "6959c0dc-fd6f-4844-8d61-ffb3fc619c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV Sample (Spark):\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal.length|sepal.width|petal.length|petal.width|variety|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load datasets using Spark\n",
        "iris_csv_spark = spark.read.csv(\"/content/drive/MyDrive/Datasets/Iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show a few rows\n",
        "print(\"CSV Sample (Spark):\")\n",
        "iris_csv_spark.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6V-KwffBIWO",
        "outputId": "d2414caf-7301-4b77-999b-6528d8aebfea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Spark CSV Schema:\n",
            "root\n",
            " |-- sepal.length: double (nullable = true)\n",
            " |-- sepal.width: double (nullable = true)\n",
            " |-- petal.length: double (nullable = true)\n",
            " |-- petal.width: double (nullable = true)\n",
            " |-- variety: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSpark CSV Schema:\")\n",
        "iris_csv_spark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAGdtatMOKcA",
        "outputId": "c140641e-a818-4cce-b0ae-b57d67d9a516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sepal.length\n",
            "sepal.width\n",
            "petal.length\n",
            "petal.width\n",
            "variety\n"
          ]
        }
      ],
      "source": [
        "for col_name in iris_csv_spark.columns:\n",
        "    print(col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXkgV3JjOPbJ"
      },
      "outputs": [],
      "source": [
        "iris_csv_spark = iris_csv_spark.withColumnRenamed(\"sepal.width\", \"sepal_width\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0finVp4vOY9d"
      },
      "outputs": [],
      "source": [
        "iris_csv_spark = iris_csv_spark.withColumnRenamed(\"sepal.length\", \"sepal_length\")\n",
        "iris_csv_spark = iris_csv_spark.withColumnRenamed(\"petal.length\", \"petal_length\")\n",
        "iris_csv_spark = iris_csv_spark.withColumnRenamed(\"petal.width\", \"petal_width\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8CvwP3Te7FN",
        "outputId": "392352af-16bd-4155-c02f-4b7b5111c4eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|variety|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| Setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| Setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| Setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| Setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| Setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Choose one format for the demo\n",
        "df = iris_csv_spark\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqqGREicfBoM"
      },
      "outputs": [],
      "source": [
        "# Define flower size classification based on petal length\n",
        "def classify_by_petal_length(petal_length):\n",
        "    if petal_length < 2.0:\n",
        "        return \"Small\"\n",
        "    elif 2.0 <= petal_length < 5.0:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Large\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh_r4-5mBMK_"
      },
      "outputs": [],
      "source": [
        "# Define flower size classification based on sepal width\n",
        "def classify_by_sepal_width(sepal_width):\n",
        "    if sepal_width < 3.0:\n",
        "        return \"Narrow\"\n",
        "    elif 3.0 <= sepal_width < 3.5:\n",
        "        return \"Moderate\"\n",
        "    else:\n",
        "        return \"Wide\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-xiNjgyBUNw"
      },
      "outputs": [],
      "source": [
        "# Register the functions as UDFs\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "petal_size_udf = udf(classify_by_petal_length, StringType())\n",
        "sepal_size_udf = udf(classify_by_sepal_width, StringType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFCIXnrykhhR",
        "outputId": "0448206d-7053-453d-952b-4f2057f2cdd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----------+------------+-----------+-------+----------+----------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|variety|petal_size|sepal_size|\n",
            "+------------+-----------+------------+-----------+-------+----------+----------+\n",
            "|         5.1|        3.5|         1.4|        0.2| Setosa|     Small|      Wide|\n",
            "|         4.9|        3.0|         1.4|        0.2| Setosa|     Small|  Moderate|\n",
            "|         4.7|        3.2|         1.3|        0.2| Setosa|     Small|  Moderate|\n",
            "|         4.6|        3.1|         1.5|        0.2| Setosa|     Small|  Moderate|\n",
            "|         5.0|        3.6|         1.4|        0.2| Setosa|     Small|      Wide|\n",
            "|         5.4|        3.9|         1.7|        0.4| Setosa|     Small|      Wide|\n",
            "|         4.6|        3.4|         1.4|        0.3| Setosa|     Small|  Moderate|\n",
            "|         5.0|        3.4|         1.5|        0.2| Setosa|     Small|  Moderate|\n",
            "|         4.4|        2.9|         1.4|        0.2| Setosa|     Small|    Narrow|\n",
            "|         4.9|        3.1|         1.5|        0.1| Setosa|     Small|  Moderate|\n",
            "+------------+-----------+------------+-----------+-------+----------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply UDFs to CSV DataFrame\n",
        "iris_classified = iris_csv_spark.withColumn(\"petal_size\", petal_size_udf(\"petal_length\")) \\\n",
        "                          .withColumn(\"sepal_size\", sepal_size_udf(\"sepal_width\"))\n",
        "\n",
        "iris_classified.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oDL7p1XZ5TT"
      },
      "outputs": [],
      "source": [
        "# Save to JSON\n",
        "iris_classified.write.mode(\"overwrite\").json(\"output/iris_transformed.json\")\n",
        "\n",
        "# Save to Parquet\n",
        "iris_classified.write.mode(\"overwrite\").parquet(\"output/iris_transformed.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l73KYZ0PZ-mW",
        "outputId": "e76fcf8c-fad1-43a1-e04d-ee332143f0fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---------+---+\n",
            "|   name|     city|age|\n",
            "+-------+---------+---+\n",
            "|  Alice|   Mumbai| 28|\n",
            "|    Bob|    Delhi| 34|\n",
            "|Charlie|Bangalore| 25|\n",
            "|  Debra|Hyderabad| 31|\n",
            "+-------+---------+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create and Show New DataFrame\n",
        "data = [\n",
        "    (\"Alice\", \"Mumbai\", 28),\n",
        "    (\"Bob\", \"Delhi\", 34),\n",
        "    (\"Charlie\", \"Bangalore\", 25),\n",
        "    (\"Debra\", \"Hyderabad\", 31)\n",
        "]\n",
        "\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "\n",
        "df_people = spark.createDataFrame(data, columns)\n",
        "df_people.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzc6GDDTaFyp"
      },
      "outputs": [],
      "source": [
        "# Save to CSV\n",
        "df_people.write.mode(\"overwrite\").option(\"header\", True).csv(\"output/people.csv\")\n",
        "\n",
        "# Save to TSV\n",
        "df_people.write.mode(\"overwrite\").option(\"header\", True).option(\"delimiter\", \"\\t\").csv(\"output/people.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUnYPfgzY_u6"
      },
      "source": [
        "### CSV vs TSV\n",
        "\n",
        "- **CSV (Comma Separated Values)**: Fields are separated using commas.\n",
        "  - Commonly used for spreadsheets and simple data interchange.\n",
        "  - Can cause issues if commas are part of field values (needs quoting).\n",
        "\n",
        "- **TSV (Tab Separated Values)**: Fields are separated using tabs (`\\t`).\n",
        "  - Less ambiguity with commas in text fields.\n",
        "  - Better for datasets containing natural language or punctuation.\n",
        "\n",
        "**Why Save to Multiple Formats?**\n",
        "- **CSV**: Human-readable and widely supported.\n",
        "- **JSON**: Semi-structured, useful for hierarchical data and APIs.\n",
        "- **Parquet**: Columnar format; optimized for performance and analytics.\n",
        "\n",
        "Each format serves different use cases â€“ it's good practice to understand and use them accordingly."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
