{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1-2CknMQKvi"
      },
      "source": [
        "### Objective\n",
        "\n",
        "In this notebook, learners will practice data cleaning techniques using PySpark. They will:\n",
        "\n",
        "- Load CSV data into a DataFrame  \n",
        "- Standardize text fields by trimming and lowering case\n",
        "- Convert columns to appropriate data types  \n",
        "\n",
        "These steps are foundational for preparing real-world data for analysis or machine learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2Plr9AWAl09"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import TimestampType, DoubleType\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "import uuid\n",
        "from pyspark.sql.functions import when, lower, trim, col\n",
        "\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataCleaning\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMldvBlvBEPf",
        "outputId": "8b8fc3d8-b840-4963-8e7e-ccaff386a188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------------+----------+----------+--------------------+--------+------+---------+--------------------+\n",
            "|         event_time|event_type|product_id|       category_code|   brand| price|  user_id|        user_session|\n",
            "+-------------------+----------+----------+--------------------+--------+------+---------+--------------------+\n",
            "|2019-11-12 23:25:59|      view|   1004258|furniture.living_...| samsung|271.43|643516476|248723df-6dec-4bf...|\n",
            "|2019-11-05 01:18:10|  purchase|  12708937|  computers.notebook|michelin|315.69|962838478|a8f877c7-ce3a-41d...|\n",
            "|2019-11-17 18:39:50|  purchase|   1003461|appliances.kitche...|   apple|954.49|394739190|08a5bbaa-6654-47a...|\n",
            "|2019-11-18 11:05:51|     click|   3601530|  computers.notebook|michelin|301.05|293348677|3bbc9541-7227-4be...|\n",
            "|2019-11-01 20:47:02|  purchase|   1590604|electronics.smart...|  janome|914.37|400669603|60810324-9779-4e4...|\n",
            "+-------------------+----------+----------+--------------------+--------+------+---------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define a helper function to generate random dates\n",
        "def generate_random_dates(start_date, end_date, n):\n",
        "    start_timestamp = datetime.strptime(start_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "    end_timestamp = datetime.strptime(end_date, \"%Y-%m-%d %H:%M:%S\")\n",
        "    delta = end_timestamp - start_timestamp\n",
        "\n",
        "    dates = []\n",
        "    for _ in range(n):\n",
        "        random_days = random.randint(0, delta.days)\n",
        "        random_seconds = random.randint(0, 86400)  # random seconds within a day\n",
        "        random_date = start_timestamp + timedelta(days=random_days, seconds=random_seconds)\n",
        "        dates.append(random_date.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
        "\n",
        "    return dates\n",
        "\n",
        "# Define possible values for product, category, and brand\n",
        "products = [1003461, 5000088, 17302664, 3601530, 1004775, 1306894, 1306421, 1590604, 12708937, 1004258]\n",
        "categories = [\"electronics.smartphone\", \"appliances.sewing_machine\", \"appliances.kitchen.washer\", \"computers.notebook\", \"furniture.living_room.sofa\"]\n",
        "brands = [\"xiaomi\", \"janome\", \"creed\", \"lg\", \"hp\", \"rondell\", \"michelin\", \"apple\", \"samsung\", \"huawei\"]\n",
        "event_types = [\"view\", \"click\", \"purchase\"]\n",
        "\n",
        "# Generate sample data\n",
        "n = 1000  # number of rows\n",
        "start_date = \"2019-11-01 00:00:00\"\n",
        "end_date = \"2019-11-30 23:59:59\"\n",
        "\n",
        "# Generate random data\n",
        "dates = generate_random_dates(start_date, end_date, n)\n",
        "event_types = [random.choice(event_types) for _ in range(n)]\n",
        "product_ids = [random.choice(products) for _ in range(n)]\n",
        "category_codes = [random.choice(categories) for _ in range(n)]\n",
        "brands = [random.choice(brands) for _ in range(n)]\n",
        "prices = [round(random.uniform(20.0, 1000.0), 2) for _ in range(n)]  # random prices between 20 and 1000\n",
        "user_ids = [random.randint(100000000, 999999999) for _ in range(n)]\n",
        "user_sessions = [str(uuid.uuid4()) for _ in range(n)]  # generate random UUIDs\n",
        "\n",
        "# Create the DataFrame\n",
        "data = list(zip(dates, event_types, product_ids, category_codes, brands, prices, user_ids, user_sessions))\n",
        "columns = [\"event_time\", \"event_type\", \"product_id\", \"category_code\", \"brand\", \"price\", \"user_id\", \"user_session\"]\n",
        "\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Show a sample of the data\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6V-KwffBIWO",
        "outputId": "40bb1716-4dbb-4492-f8f0-36acac20477d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------------------+--------+\n",
            "|event_type|       category_code|   brand|\n",
            "+----------+--------------------+--------+\n",
            "|      view|furniture.living_...| samsung|\n",
            "|  purchase|  computers.notebook|michelin|\n",
            "|  purchase|appliances.kitche...|   apple|\n",
            "|     click|  computers.notebook|michelin|\n",
            "|  purchase|electronics.smart...|  janome|\n",
            "+----------+--------------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Apply trimming and lowercase to string columns\n",
        "df_cleaned = df.withColumn(\"event_type\", lower(trim(col(\"event_type\")))) \\\n",
        "               .withColumn(\"category_code\", lower(trim(col(\"category_code\")))) \\\n",
        "               .withColumn(\"brand\", lower(trim(col(\"brand\"))))\n",
        "\n",
        "df_cleaned.select(\"event_type\", \"category_code\", \"brand\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAGdtatMOKcA",
        "outputId": "3de4e3ed-8c9d-4b40-a8d9-41729f9736c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------+------+\n",
            "|       category_code|   brand| price|\n",
            "+--------------------+--------+------+\n",
            "|furniture.living_...| samsung|271.43|\n",
            "|  computers.notebook|michelin|315.69|\n",
            "|appliances.kitche...|   apple|954.49|\n",
            "|  computers.notebook|michelin|301.05|\n",
            "|electronics.smart...|  janome|914.37|\n",
            "+--------------------+--------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Replace \"N/A\", \"unknown\", empty strings with null\n",
        "for col_name in [\"category_code\", \"brand\"]:\n",
        "    df_cleaned = df_cleaned.withColumn(\n",
        "        col_name,\n",
        "        when(col(col_name).isin(\"N/A\", \"unknown\", \"\"), None).otherwise(col(col_name))\n",
        "    )\n",
        "\n",
        "# Fill missing values with defaults\n",
        "df_filled = df_cleaned.fillna({\n",
        "    \"category_code\": \"unspecified\",\n",
        "    \"brand\": \"unbranded\",\n",
        "    \"price\": 0.0\n",
        "})\n",
        "\n",
        "df_filled.select(\"category_code\", \"brand\", \"price\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXkgV3JjOPbJ",
        "outputId": "cbadc075-cc91-4db1-9cb0-66e9582f83a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- event_time: timestamp (nullable = true)\n",
            " |-- event_type: string (nullable = true)\n",
            " |-- product_id: long (nullable = true)\n",
            " |-- category_code: string (nullable = false)\n",
            " |-- brand: string (nullable = false)\n",
            " |-- price: double (nullable = false)\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- user_session: string (nullable = true)\n",
            "\n",
            "+-------------------+------+\n",
            "|         event_time| price|\n",
            "+-------------------+------+\n",
            "|2019-11-12 23:25:59|271.43|\n",
            "|2019-11-05 01:18:10|315.69|\n",
            "|2019-11-17 18:39:50|954.49|\n",
            "|2019-11-18 11:05:51|301.05|\n",
            "|2019-11-01 20:47:02|914.37|\n",
            "+-------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Convert 'event_time' to Timestamp and ensure 'price' is float\n",
        "df_typed = df_filled.withColumn(\"event_time\", col(\"event_time\").cast(TimestampType())) \\\n",
        "                    .withColumn(\"price\", col(\"price\").cast(DoubleType()))\n",
        "\n",
        "df_typed.printSchema()\n",
        "df_typed.select(\"event_time\", \"price\").show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVvjociwlqAS"
      },
      "source": [
        "### Summary\n",
        "\n",
        "In this notebook, we learned how to:\n",
        "\n",
        "- Load raw CSV data into a PySpark DataFrame  \n",
        "- Standardize and clean string fields using `trim()` and `lower()`  \n",
        "- Replace placeholder strings with nulls, and fill in default values  \n",
        "- Convert string columns like `event_time` into proper timestamp format"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
